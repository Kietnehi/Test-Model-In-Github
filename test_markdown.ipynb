{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6809ee30",
   "metadata": {},
   "source": [
    "\n",
    "## ü§ñ Repository Purpose\n",
    "\n",
    "This repository is used to **test and experiment with various open-source projects on GitHub** related to:\n",
    "\n",
    "- Artificial Intelligence (AI)  \n",
    "- Machine Learning (ML)  \n",
    "- Deep Learning (DL)  \n",
    "\n",
    "The main purpose of this repository is for learning, research, and hands-on experimentation with modern AI models.\n",
    "\n",
    "\n",
    "## üéôÔ∏è Tested Models\n",
    "\n",
    "Currently, this repository has successfully tested the following model:\n",
    "\n",
    "### üîπ VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://github.com/OpenBMB/VoxCPM\" target=\"_blank\" title=\"Click to open the original VoxCPM repository\">\n",
    "    <img src=\"VoxCBM/assets/voxcpm_logo.png\" width=\"280\" alt=\"VoxCPM Logo\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  üîó <b>Click the logo to visit the official VoxCPM source code</b>\n",
    "</p>\n",
    "\n",
    "- Tokenizer-free Text-to-Speech model  \n",
    "- Context-aware expressive speech generation  \n",
    "- High-quality zero-shot voice cloning  \n",
    "\n",
    "üîó **Official Source:** https://github.com/OpenBMB/VoxCPM\n",
    "\n",
    "\n",
    "This project focuses on evaluating the real-world usability of advanced TTS and voice cloning models.\n",
    "\n",
    "- **Readme:** [VoxCBM README](VoxCBM/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Open-Source LLM (Reasoning)\n",
    "\n",
    "- **Tested:** I evaluated an open-source LLM that demonstrates reasoning capabilities (chain-of-thought style reasoning and problem solving). Notes and brief results from that evaluation are included in this repository.\n",
    " \n",
    "<p align=\"center\">\n",
    "  <a href=\"https://huggingface.co/\">\n",
    "    <img src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" width=\"180\" alt=\"Hugging Face Logo\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "- **Browse trending models:** [Explore trending text-generation models on Hugging Face](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending)\n",
    "\n",
    "- **Readme:** [LLM_Reasoning_Model README](LLM_Reasoning_Model/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ LangExtract ‚Äî Structured Data Extraction with LLMs\n",
    "\n",
    "\n",
    "![LangExtract Demo](https://raw.githubusercontent.com/google/langextract/main/docs/_static/romeo_juliet_basic.gif)\n",
    "\n",
    "üîó GitHub Repository: https://github.com/google/langextract?tab=readme-ov-file  \n",
    "\n",
    "- **Readme:** [LangExtract README](LangExtract/README.md)\n",
    "\n",
    "**LangExtract** is a Python library that uses Large Language Models (LLMs) to extract structured information from unstructured text documents based on user-defined instructions.\n",
    "\n",
    "### ‚ú® Key Capabilities\n",
    "\n",
    "- **Structured Data Extraction**  \n",
    "  Converts raw text (such as clinical notes, reports, or novels) into organized, structured data outputs.\n",
    "\n",
    "- **Precise Source Grounding**  \n",
    "  Maps every extracted entity back to its exact location in the original source text, making verification easy and reliable.\n",
    "\n",
    "- **Long Document Processing**  \n",
    "  Handles large documents using text chunking, parallel processing, and multiple extraction passes to ensure high recall.\n",
    "\n",
    "- **Interactive Visualization**  \n",
    "  Generates self-contained HTML files that allow you to visually review extracted entities directly in their original context.\n",
    "---\n",
    "\n",
    "### üîπ LEANN ‚Äî Ultra-Lightweight Vector Index for Local RAG\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://github.com/yichuan-w/LEANN\" target=\"_blank\">\n",
    "    <img src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/logo-text.png\" width=\"260\" alt=\"LEANN Logo\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "- Ultra-lightweight vector index with up to **97% storage saving**  \n",
    "- Fully local & privacy-preserving Retrieval-Augmented Generation (RAG)  \n",
    "- Supports documents, code, chat history, email, and live data via MCP  \n",
    "\n",
    "üîó **Official Source:** https://github.com/yichuan-w/LEANN  \n",
    "\n",
    "- **Readme:** [LEAN README](LEAN/README.md)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Crawl4AI ‚Äî Web Data Extraction for LLM & AI\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSNAy1PPvsqXeZ9XPifYY3F5TP4SAgUZfQedw&s\" width=\"220\" alt=\"Crawl4AI Logo\"/>\n",
    "</p>\n",
    "\n",
    "**Crawl4AI** is an open-source Python library for web crawling and scraping, designed to convert HTML content into clean, structured data (Markdown/JSON) optimized for LLMs and AI applications.\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "- **AI-Optimized Output:** Removes ads, menus, and clutter; reduces token count; exports Markdown/JSON ready for LLM ingestion.\n",
    "- **Dynamic Web Handling:** Uses Playwright to render JavaScript, enabling crawling of SPAs and lazy-loaded content.\n",
    "- **High Performance:** Supports async crawling, multiple URLs at once, and caching.\n",
    "- **Smart Extraction:** CSS/XPath selectors, content clustering, and LLM-powered extraction.\n",
    "- **Free & Self-Hosted:** Open source, no paid APIs required, runs locally or on your own server.\n",
    "\n",
    "üëâ **In short:** Crawl4AI is a web crawling tool purpose-built to create ‚Äúclean, instantly usable‚Äù data for AI/LLM projects.\n",
    "\n",
    "- **Readme:** [Github Repository Crawl4AI](https://github.com/unclecode/crawl4ai)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ DuckDuckGo Search ‚Äî Automated Web Search for AI & Data Projects\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/duckduckgo.png\" style=\"max-width:50%; height:auto;\" alt=\"DuckDuckGo Logo\"/>\n",
    "</p>\n",
    "\n",
    "The `duckduckgo-search` package (now renamed to `ddgs`) in Python is mainly used to **automate web searching** without using a browser, serving applications that require up-to-date data.\n",
    "\n",
    "#### üì• Installation\n",
    "\n",
    "```bash\n",
    "pip install duckduckgo-search\n",
    "pip install -U ddgs\n",
    "```\n",
    "\n",
    "> ‚ö†Ô∏è The package was renamed from `duckduckgo-search` to **`ddgs`**.\n",
    "> You can install either the legacy name or the updated package as shown above.\n",
    "\n",
    "---\n",
    "#### Key Features\n",
    "\n",
    "* **Purpose**: Retrieve search results (text, images, news, videos) directly in Python code.\n",
    "* **Use cases**:\n",
    "  * Automated news aggregation and research tools\n",
    "  * Collecting data for AI/ML projects (real-time data for LLMs via LangChain, etc.)\n",
    "  * Automating the search and download of documents (PDF, DOC, etc.)\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: This package has been renamed from `duckduckgo-search` to **`ddgs`**. Install with: `pip install ddgs`\n",
    "\n",
    "#### Other Ways to Use DuckDuckGo in Python\n",
    "\n",
    "| Method                    | Main Purpose                                                           | Notes                                                       |\n",
    "| ------------------------- | ---------------------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| **`ddgs` package**        | Flexible automated web searching                                       | Most popular and easiest to use                             |\n",
    "| **LangChain integration** | Connect search with AI models (LLMs) to build intelligent applications | Used when building AI assistants or search-enabled chatbots |\n",
    "| **Direct HTML scraping**  | Collect data when there is no official API                             | More complex and fragile if the page structure changes      |\n",
    "\n",
    "#### üñ•Ô∏è How to Test DuckDuckGo UI\n",
    "\n",
    "If you want to test or run the DuckDuckGo search UI, please go to the `duckduckgo-ui` folder and read the file [duckduckgo-ui/README.md](duckduckgo-ui/README.md) for detailed setup and usage instructions.\n",
    "\n",
    "#### Practical Applications\n",
    "\n",
    "* **News aggregation**: Automatically search for and summarize the latest news on a topic.\n",
    "* **Automated research**: Collect information and academic articles from the web.\n",
    "* **Providing data for AI**: Help chatbots answer questions about the latest events.\n",
    "\n",
    "**Original GitHub repository:** [https://github.com/deedy5/ddgs](https://github.com/deedy5/ddgs)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### üîπ Tavily API Search ‚Äî Automated Web Search, Crawling & Extraction\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/tavily.jpg\" width=\"300\" alt=\"Tavily Logo\"/>\n",
    "</div>\n",
    "\n",
    "The `Tavily_APi_Search` folder provides scripts for automating web search, crawling, and data extraction using the Tavily API:\n",
    "\n",
    "* **basic_or_advance_search.py**: Perform both basic and advanced searches with Tavily API.\n",
    "* **crawl.py**: Crawl web pages and collect data from URLs.\n",
    "* **extract.py**: Extract structured information from crawled content.\n",
    "* **research.py**: Automate research tasks and poll for results from Tavily API.\n",
    "* **test_full.py**: Full-featured testing of Tavily API capabilities.\n",
    "* **test_map.py**: Demonstrate mapping or location-based search features.\n",
    "\n",
    "üîó **Original GitHub tavily-python repository:** [https://github.com/tavily-ai/tavily-python](https://github.com/tavily-ai/tavily-python)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ YouTube API & yt-dlp ‚Äî Download & Transcript Extraction\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/youtube.png\" width=\"300\" alt=\"YouTube Logo\"/>\n",
    "</div>\n",
    "\n",
    "**yt-dlp** is a powerful tool for downloading videos, audio, and subtitles from YouTube and many other platforms. Combine it with **youtube-transcript-api** to automatically extract transcripts (subtitles) from YouTube videos directly in Python.\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "* Download video/audio in various qualities\n",
    "* Download playlists and multilingual subtitles\n",
    "* Extract transcripts (subtitles) automatically or from user-uploaded captions\n",
    "* Easily integrate into AI, NLP, and data aggregation workflows\n",
    "\n",
    "üîó **Original GitHub yt-dlp repository:** [https://github.com/yt-dlp/yt-dlp](https://github.com/yt-dlp/yt-dlp)\n",
    "\n",
    "üîó **Original GitHub youtube-transcript-api repository:** [https://github.com/jdepoix/youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "‚ú® More open-source AI models will be added and tested in this repository in the future.\n",
    "\n",
    "\n",
    "### üîπ Gemini API Tool ‚Äî Google Gemini AI & Data Utilities\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/gemini.jpg\" width=\"300\" alt=\"Gemini Logo\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "The `GEMINI_API_TOOL` folder provides scripts and notebooks for working with Google Gemini API and related data tasks:\n",
    "\n",
    "* **Code_Execution.ipynb**: Jupyter notebook for running and testing Gemini API code, including code samples and data processing demos.\n",
    "* **google_map.py**: Script for interacting with Google Maps, possibly using Gemini API for geolocation or mapping tasks.\n",
    "* **sales.csv**: Example sales data for analysis or demo purposes.\n",
    "* **Search_Citation.py**: Script for searching and generating citations, leveraging Gemini API or other search APIs.\n",
    "\n",
    "üîó **Google AI Studio:** [https://aistudio.google.com/](https://aistudio.google.com/)\n",
    "\n",
    "üîó **Gemini API Documentation:** [https://ai.google.dev/gemini-api/docs](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "\n",
    "### üîπ Text To Speech Vietnamese\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/tts.jpg\" width=\"300\" alt=\"Text To Speech Vietnamese\"/>\n",
    "</div>\n",
    "\n",
    "The **Text To Speech Vietnamese** module provides multiple scripts for converting Vietnamese text into speech using different TTS engines, both **online** and **offline**:\n",
    "\n",
    "* **vieneu-tts.py**: Vietnamese TTS using `vieneu` with `espeak-ng`, suitable for offline environments.  \n",
    "  üîó Documentation: https://github.com/pnnbao97/VieNeu-TTS\n",
    "\n",
    "* **edge-tts.py**: High-quality Vietnamese voice using Microsoft Edge Text-To-Speech (online).  \n",
    "  üîó Documentation: https://github.com/rany2/edge-tts\n",
    "\n",
    "* **gTts.py**: Vietnamese TTS via Google Translate using `gTTS` (online).  \n",
    "  üîó Documentation: https://pypi.org/project/gTTS/\n",
    "\n",
    "* **pyttsx3-tts.py**: Offline text-to-speech using system TTS engines through `pyttsx3`.  \n",
    "  üîó Documentation: https://pypi.org/project/pyttsx3/\n",
    "\n",
    "### üîß Supported Features\n",
    "- üáªüá≥ Vietnamese language support\n",
    "- üåê Online & Offline TTS options\n",
    "- üß™ Easy testing with Python scripts\n",
    "- üíª Cross-platform (Windows / Linux / macOS)\n",
    "\n",
    "> **Note:**\n",
    "> - Voice quality depends on the selected TTS engine.\n",
    "> - `edge-tts` provides the best natural Vietnamese voice but requires Internet.\n",
    "> - `pyttsx3` works fully offline but voice quality depends on OS.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Author's Github\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src=\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=120&section=header\"/>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://github.com/Kietnehi\">\n",
    "    <img src=\"https://github.com/Kietnehi.png\" width=\"140\" height=\"140\" style=\"border-radius: 50%; border: 4px solid #A371F7;\" alt=\"Avatar Tr∆∞∆°ng Ph√∫ Ki·ªát\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "<h3>üöÄ Tr∆∞∆°ng Ph√∫ Ki·ªát</h3>\n",
    "\n",
    "<a href=\"https://github.com/Kietnehi\">\n",
    "  <img src=\"https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&color=236AD3&background=00000000&center=true&vCenter=true&width=435&lines=Student+@+Sai+Gon+University;Fullstack+Dev+%26+AI+Researcher;Test+Model+In+Github\" alt=\"Typing SVG\" />\n",
    "</a>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://img.shields.io/badge/SGU-Sai_Gon_University-0056D2?style=flat-square&logo=google-scholar&logoColor=white\" alt=\"SGU\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Base-Ho_Chi_Minh_City-FF4B4B?style=flat-square&logo=google-maps&logoColor=white\" alt=\"HCMC\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://github.com/Kietnehi?tab=followers\">\n",
    "    <img src=\"https://img.shields.io/github/followers/Kietnehi?label=Followers&style=flat-square&logo=github\"/>\n",
    "  </a>\n",
    "  <a href=\"https://github.com/Kietnehi\">\n",
    "    <img src=\"https://img.shields.io/github/stars/Kietnehi?label=Stars&style=flat-square&logo=github\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "<h3>üõ† Tech Stack</h3>\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://skillicons.dev\">\n",
    "    <img src=\"https://skillicons.dev/icons?i=docker,python,react,nodejs,mongodb,git,fastapi,pytorch&theme=light\" alt=\"My Skills\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h3>üåü AI Model Demos & Experiments</h3>\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://github.com/Kietnehi/Test-Model-In-Github\">\n",
    "    <img src=\"https://img.shields.io/github/stars/Kietnehi/Test-Model-In-Github?style=for-the-badge&color=yellow\" alt=\"Stars\"/>\n",
    "    <img src=\"https://img.shields.io/github/forks/Kietnehi/Test-Model-In-Github?style=for-the-badge&color=orange\" alt=\"Forks\"/>\n",
    "    <img src=\"https://img.shields.io/github/issues/Kietnehi/Test-Model-In-Github?style=for-the-badge&color=red\" alt=\"Issues\"/>\n",
    "  </a>\n",
    "</p>\n",
    "<!-- Quote ƒë·ªông -->\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://quotes-github-readme.vercel.app/api?type=horizontal&theme=dark\" alt=\"Daily Quote\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<i>Thank you for stopping by! Don‚Äôt forget to give this repo a <b>‚≠êÔ∏è Star</b> if you find it useful.</i>\n",
    "\n",
    "</p>\n",
    "\n",
    "<img src=\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=80&section=footer\"/>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647575c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Thay c√°i ID d∆∞·ªõi ƒë√¢y b·∫±ng ID \"An\" b·∫°n v·ª´a t√¨m th·∫•y trong danh s√°ch\n",
    "vi_voice_id = r\"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_VI-VN_AN_11.0\"\n",
    "\n",
    "engine.setProperty('voice', vi_voice_id)\n",
    "engine.setProperty('rate', 150) # T·ªëc ƒë·ªô n√≥i\n",
    "engine.say(\"Ch√†o b·∫°n, b√¢y gi·ªù t√¥i ƒë√£ c√≥ th·ªÉ n√≥i ti·∫øng Vi·ªát offline r·ªìi.\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdc8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44f489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4170a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea4725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db725a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
