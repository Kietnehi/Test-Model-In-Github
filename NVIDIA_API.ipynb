{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff79396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>The user has sent a message that just contains \" \" - this appears to be an empty or whitespace-only message. \n",
      "\n",
      "I should respond appropriately to this. Since there's no actual content to respond to, I should:\n",
      "1. Acknowledge that I received their message\n",
      "2. Perhaps ask them what they'd like help with\n",
      "3. Keep it friendly and professional\n",
      "\n",
      "Let me craft a simple, helpful response.\n",
      "</think>\n",
      "\n",
      "Hello! I received your message, but it appears to be empty. \n",
      "\n",
      "I'm here to help you with a wide range of tasks, including:\n",
      "\n",
      "- Writing, editing, and improving text\n",
      "- Answering questions and explaining concepts\n",
      "- Coding and technical problem-solving\n",
      "- Brainstorming ideas\n",
      "- Analysis and research\n",
      "- And much more!\n",
      "\n",
      "What would you like assistance with today?"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # tự tìm file .env cùng thư mục\n",
    "\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = NVIDIA_API_KEY\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"minimaxai/minimax-m2.1\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"\"}],\n",
    "  temperature=1,\n",
    "  top_p=0.95,\n",
    "  max_tokens=8192,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if not getattr(chunk, \"choices\", None):\n",
    "    continue\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL RESPONSE ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# =========================\n",
    "# Load ENV\n",
    "# =========================\n",
    "load_dotenv()\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "invoke_url = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n",
    "stream = True\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NVIDIA_API_KEY}\",\n",
    "    \"Accept\": \"text/event-stream\" if stream else \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"moonshotai/kimi-k2.5\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Giải thích ngắn gọn sự khác nhau giữa AI và Machine Learning\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 512 * 10,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1.0,\n",
    "    \"stream\": True,\n",
    "    \"chat_template_kwargs\": {\n",
    "        \"thinking\": True\n",
    "    },\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Request (QUAN TRỌNG)\n",
    "# =========================\n",
    "response = requests.post(\n",
    "    invoke_url,\n",
    "    headers=headers,\n",
    "    json=payload,\n",
    "    stream=True,\n",
    "    timeout=(10, None),  # ⬅️ FIX TIMEOUT 100%\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Stream Response\n",
    "# =========================\n",
    "if stream:\n",
    "    print(\"=== MODEL RESPONSE ===\\n\")\n",
    "\n",
    "    for line in response.iter_lines(decode_unicode=True):\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # SSE format: data: {...}\n",
    "        if line.startswith(\"data:\"):\n",
    "            data = line[5:].strip()\n",
    "\n",
    "            if data == \"[DONE]\":\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                chunk = json.loads(data)\n",
    "                delta = chunk[\"choices\"][0][\"delta\"]\n",
    "\n",
    "                if \"content\" in delta:\n",
    "                    print(delta[\"content\"], end=\"\", flush=True)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "else:\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # tự tìm file .env cùng thư mục\n",
    "\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "_USE_COLOR = sys.stdout.isatty() and os.getenv(\"NO_COLOR\") is None\n",
    "_REASONING_COLOR = \"\\033[90m\" if _USE_COLOR else \"\"\n",
    "_RESET_COLOR = \"\\033[0m\" if _USE_COLOR else \"\"\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = os.getenv(\"NVIDIA_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"z-ai/glm4.7\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"\"}],\n",
    "  temperature=1,\n",
    "  top_p=1,\n",
    "  max_tokens=16384,\n",
    "  extra_body={\"chat_template_kwargs\":{\"enable_thinking\":True,\"clear_thinking\":False}},\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if not getattr(chunk, \"choices\", None):\n",
    "    continue\n",
    "  if len(chunk.choices) == 0 or getattr(chunk.choices[0], \"delta\", None) is None:\n",
    "    continue\n",
    "  delta = chunk.choices[0].delta\n",
    "  reasoning = getattr(delta, \"reasoning_content\", None)\n",
    "  if reasoning:\n",
    "    print(f\"{_REASONING_COLOR}{reasoning}{_RESET_COLOR}\", end=\"\")\n",
    "  if getattr(delta, \"content\", None) is not None:\n",
    "    print(delta.content, end=\"\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # tự tìm file .env cùng thư mục\n",
    "\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = os.getenv(\"NVIDIA_API_KEY\")\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"deepseek-ai/deepseek-v3.2\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"\"}],\n",
    "  temperature=1,\n",
    "  top_p=0.95,\n",
    "  max_tokens=8192,\n",
    "  extra_body={\"chat_template_kwargs\": {\"thinking\":True}},\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if not getattr(chunk, \"choices\", None):\n",
    "    continue\n",
    "  reasoning = getattr(chunk.choices[0].delta, \"reasoning_content\", None)\n",
    "  if reasoning:\n",
    "    print(reasoning, end=\"\")\n",
    "  if chunk.choices and chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de9405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
