D∆∞·ªõi ƒë√¢y l√† b·∫£n **t√≥m t·∫Øt ng·∫Øn g·ªçn c√°c √Ω ch√≠nh v√† ph·∫ßn c·∫ßn thi·∫øt** c·ªßa LangExtract ƒë·ªÉ b·∫°n c√≥ th·ªÉ ƒë∆∞a tr·ª±c ti·∫øp v√†o README.

---

## LangExtract ‚Äì T√≥m t·∫Øt nhanh cho README

### Gi·ªõi thi·ªáu

**LangExtract** l√† th∆∞ vi·ªán Python d√πng LLM ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c t·ª´ vƒÉn b·∫£n kh√¥ng c·∫•u tr√∫c (clinical notes, b√°o c√°o, t√†i li·ªáu d√†i‚Ä¶) d·ª±a tr√™n prompt v√† v√≠ d·ª• ng∆∞·ªùi d√πng cung c·∫•p.

---

### T√≠nh nƒÉng ch√≠nh

* üéØ **Grounding ch√≠nh x√°c**: M·ªói extraction ƒë∆∞·ª£c g·∫Øn ƒë√∫ng v·ªã tr√≠ trong vƒÉn b·∫£n g·ªëc.
* üì¶ **Output c√≥ c·∫•u tr√∫c ·ªïn ƒë·ªãnh**: Tu√¢n theo schema v√† v√≠ d·ª• few-shot.
* üìö **X·ª≠ l√Ω t√†i li·ªáu d√†i**: Chia nh·ªè, ch·∫°y song song, nhi·ªÅu l∆∞·ª£t ƒë·ªÉ tƒÉng recall.
* üñ•Ô∏è **Visual h√≥a k·∫øt qu·∫£**: Sinh file HTML t∆∞∆°ng t√°c ƒë·ªÉ ki·ªÉm tra entity trong ng·ªØ c·∫£nh.
* üîå **H·ªó tr·ª£ nhi·ªÅu model**:

  * Google Gemini (cloud)
  * OpenAI
  * Local LLM qua Ollama
* üß© **D·ªÖ m·ªü r·ªông**: Th√™m custom model provider qua plugin.

---

### C√†i ƒë·∫∑t

```bash
pip install langextract
```

---

### Thi·∫øt l·∫≠p API key (cloud models)

C√°ch khuy·∫øn ngh·ªã:

```bash
export LANGEXTRACT_API_KEY="your-api-key"
```

Ho·∫∑c d√πng file `.env`.

H·ªó tr·ª£ key t·ª´:

* Google AI Studio / Vertex AI (Gemini)
* OpenAI Platform

---

### Quick Start (v√≠ d·ª• ng·∫Øn)

```python
import langextract as lx

prompt = "Extract characters and emotions."
examples = [...]  # few-shot examples

result = lx.extract(
    text_or_documents="Lady Juliet gazed longingly at the stars...",
    prompt_description=prompt,
    examples=examples,
    model_id="gemini-2.5-flash",
)
```

---

### L∆∞u & Visualize k·∫øt qu·∫£

```python
lx.io.save_annotated_documents([result], "results.jsonl", ".")
html = lx.visualize("results.jsonl")

with open("visualization.html", "w") as f:
    f.write(html.data if hasattr(html, "data") else html)
```

---

### X·ª≠ l√Ω t√†i li·ªáu d√†i

* H·ªó tr·ª£ URL tr·ª±c ti·∫øp (VD: Project Gutenberg)
* Ch·∫°y song song + nhi·ªÅu passes:

```python
result = lx.extract(
    text_or_documents=url,
    extraction_passes=3,
    max_workers=20,
    max_char_buffer=1000
)
```

---

### D√πng OpenAI

```python
pip install langextract[openai]
```

```python
result = lx.extract(
    model_id="gpt-4o",
    fence_output=True,
    use_schema_constraints=False
)
```

---

### D√πng Local LLM v·ªõi Ollama

```python
result = lx.extract(
    model_id="gemma2:2b",
    model_url="http://localhost:11434",
    fence_output=False,
    use_schema_constraints=False
)
```

---

### M·ªü r·ªông Provider

* H·ªó tr·ª£ plugin system
* ƒêƒÉng k√Ω provider b·∫±ng `@registry.register(...)`
* Ph√¢n ph·ªëi nh∆∞ package ri√™ng

---

### Testing & Dev

```bash
pytest tests
tox
```

---

### Ghi ch√∫

* Kh√¥ng ph·∫£i s·∫£n ph·∫©m ch√≠nh th·ª©c c·ªßa Google.
* D√πng cho y t·∫ø ch·ªâ mang t√≠nh minh h·ªça, kh√¥ng thay th·∫ø t∆∞ v·∫•n chuy√™n m√¥n.
* License: Apache 2.0

---

N·∫øu b·∫°n mu·ªën, m√¨nh c√≥ th·ªÉ:

* Vi·∫øt l·∫°i b·∫£n n√†y **b·∫±ng ti·∫øng Anh chu·∫©n README**
* Ho·∫∑c r√∫t g·ªçn h∆°n n·ªØa th√†nh **1 trang ‚ÄúMinimal README‚Äù**
* Ho·∫∑c ch·ªânh theo style project hi·ªán t·∫°i c·ªßa b·∫°n (bullet, badges, sections).
